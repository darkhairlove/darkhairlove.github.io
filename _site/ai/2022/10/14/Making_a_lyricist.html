

<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>[AIFFEL]_작사가만들기 | Minimalistic</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="[AIFFEL]_작사가만들기" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="몇 단어를 적었을 때, 작사가 가능하도록 만들기" />
<meta property="og:description" content="몇 단어를 적었을 때, 작사가 가능하도록 만들기" />
<link rel="canonical" href="http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html" />
<meta property="og:url" content="http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html" />
<meta property="og:site_name" content="Minimalistic" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-10-14T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="[AIFFEL]_작사가만들기" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-10-14T00:00:00+09:00","datePublished":"2022-10-14T00:00:00+09:00","description":"몇 단어를 적었을 때, 작사가 가능하도록 만들기","headline":"[AIFFEL]_작사가만들기","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/logo.jpg"}},"url":"http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/colors-auto.css?v=7941e02880d05669064bb8fbe35fd38fa4e4dcc9">
    <link rel="stylesheet" href="/assets/css/style.css?v=7941e02880d05669064bb8fbe35fd38fa4e4dcc9">
    <link rel="preload" href="/assets/img/logo.jpg" as="image">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css">

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->

  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="wrapper">
      <div class="sidebar">
        <header>
    <div class="header-title">
        
<img class="logo" src="/assets/img/logo.jpg" alt="Logo">



<h1>Minimalistic</h1>



<p class="addr"><i class="fa-solid fa-envelope"></i>&nbsp;<a href="mailto:person@address.com">person@address.com</a></p>


    </div>
    <div class="header-title-mobile">
        <section>
        
<img class="logo" src="/assets/img/logo.jpg" alt="Logo">



<h1>Minimalistic</h1>



<p class="addr"><i class="fa-solid fa-envelope"></i>&nbsp;<a href="mailto:person@address.com">person@address.com</a></p>


        </section>
    </div>


<p>Minimalistic is a theme powered by Jekyll.</p>


    
    <p class="view"><a href="https://github.com/darkhairlove/darkhairlove.github.io">View the Project on GitHub<br><small>darkhairlove/darkhairlove.github.io</small></a></p>
    

    


<div class="link-wrapper">
  
  <ul class="link">
    <li><a href="https://github.com/vaibhavvikas"><i class="fa-brands fa-github"></i>&nbsp;GitHub</a></li>
    <li><a href="https://www.linkedin.com/in/vaibhavvikas"><i class="fa-brands fa-linkedin"></i>&nbsp;LinkedIn</a></li>
  </ul>
  

  
  <h3 class="sidebar-h3">Contents:</h3>
  <ul class="content">
    <li><a href="./index.html">Readme</a>
        
        <ul class="sublist">
            <li><a href="./index.html#small-image">Image</a></li>
        </ul>
        
    </li>
    <li><a href="./another-page.html">Another Page</a>
        
    </li>
  </ul>
  
</div>

</header>
        <div class="link-wrapper-mobile">
    
    <ul class="link">
    <nobr><a href="https://github.com/vaibhavvikas" rel="me"><i class="fa-brands fa-github"></i>&nbsp;GitHub</a><span style="margin-left: 6px;"></span></nobr>
    <nobr><a href="https://www.linkedin.com/in/vaibhavvikas" rel="me"><i class="fa-brands fa-linkedin"></i>&nbsp;LinkedIn</a></nobr>
    </ul>
    

    
    <h3 class="sidebar-h3">Contents:</h3>
    <ul class="content">
      <li><a href="./index.html">Readme</a>
          
          <ul class="sublist">
              <li><a href="./index.html#small-image">Image</a></li>
          </ul>
          
      </li>
      <li><a href="./another-page.html">Another Page</a>
          
      </li>
    </ul>
    
</div>

        <div class="sidebar-footer">
    
    <p>This project is maintained by <a href="https://github.com/darkhairlove">darkhairlove</a></p>
    

<p style="margin-bottom: 0px">
    <small>
        <a href="https://github.com/vaibhavvikas/jekyll-theme-minimalistic">Minimalistic</a> &mdash; Theme by 
        <a href="https://github.com/vaibhavvikas/">vaibhavvikas</a>
    </small>
</p>
</div>
      </div>
      <section>
      





<div id="main" role="main">
  <div class="link-wrapper">
  
  <ul class="link">
    <li><a href="https://github.com/vaibhavvikas"><i class="fa-brands fa-github"></i>&nbsp;GitHub</a></li>
    <li><a href="https://www.linkedin.com/in/vaibhavvikas"><i class="fa-brands fa-linkedin"></i>&nbsp;LinkedIn</a></li>
  </ul>
  

  
  <h3 class="sidebar-h3">Contents:</h3>
  <ul class="content">
    <li><a href="./index.html">Readme</a>
        
        <ul class="sublist">
            <li><a href="./index.html#small-image">Image</a></li>
        </ul>
        
    </li>
    <li><a href="./another-page.html">Another Page</a>
        
    </li>
  </ul>
  
</div>


  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[AIFFEL]_작사가만들기">
    <meta itemprop="description" content="몇 단어를 적었을 때, 작사가 가능하도록 만들기">
    <meta itemprop="datePublished" content="2022-10-14T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html" class="u-url" itemprop="url">[AIFFEL]_작사가만들기
</a>
          </h1>
          


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> 목차</h4></header>
              <ul class="toc__menu"><li><a href="#정제된-문자">정제된 문자</a></li><li><a href="#회고">회고</a></li></ul>

            </nav>
          </aside>
        
        <head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }
  .language-result {
    background : #ffffff00;
    font-size: 0.8rem;
    }
  </style>
</head>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="p">.</span><span class="n">mount</span><span class="p">(</span><span class="s">'/content/drive'</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-result">Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">txt_file_path</span> <span class="o">=</span> <span class="s">'/content/drive/MyDrive/Colab/AIFFEL/day/lyrics/*'</span> 

<span class="n">txt_list</span> <span class="o">=</span> <span class="n">glob</span><span class="p">.</span><span class="n">glob</span><span class="p">(</span><span class="n">txt_file_path</span><span class="p">)</span> 

<span class="n">raw_corpus</span> <span class="o">=</span> <span class="p">[]</span> 

<span class="c1"># 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담음.
</span><span class="k">for</span> <span class="n">txt_file</span> <span class="ow">in</span> <span class="n">txt_list</span><span class="p">:</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">txt_file</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">raw</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">read</span><span class="p">().</span><span class="n">splitlines</span><span class="p">()</span> 
        <span class="n">raw_corpus</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">raw</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"데이터 크기:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_corpus</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Examples:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">raw_corpus</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<pre><code class="language-result">데이터 크기: 187088
Examples:
 ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 입력된 문장을
#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다
#     2. 특수문자 양쪽에 공백을 넣고
#     3. 여러개의 공백은 하나의 공백으로 바꿉니다
#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다
#     5. 다시 양쪽 공백을 지웁니다
#     6. 문장 시작에는 &lt;start&gt;, 끝에는 &lt;end&gt;를 추가합니다
</span><span class="k">def</span> <span class="nf">preprocess_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">lower</span><span class="p">().</span><span class="n">strip</span><span class="p">()</span> <span class="c1"># 1
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"([?.!,¿])"</span><span class="p">,</span> <span class="sa">r</span><span class="s">" \1 "</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="c1"># 2
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">'[" "]+'</span><span class="p">,</span> <span class="s">" "</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="c1"># 3
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"[^a-zA-Z?.!,¿]+"</span><span class="p">,</span> <span class="s">" "</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="c1"># 4
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="c1"># 5
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="s">'&lt;start&gt; '</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="s">' &lt;end&gt;'</span> <span class="c1"># 6
</span>    <span class="k">return</span> <span class="n">sentence</span>
</code></pre></div></div>

<h2 id="정제된-문자">정제된 문자</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corpus</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">raw_corpus</span><span class="p">:</span>
    <span class="c1"># 원하지 않는 문장은 건너뜀.
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span> <span class="k">continue</span>
    <span class="k">if</span> <span class="n">sentence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s">":"</span><span class="p">:</span> <span class="k">continue</span>
    <span class="n">preprocessed_sentence</span> <span class="o">=</span> <span class="n">preprocess_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="c1"># 토큰의 개수가 15개를 넘어가는 문장 제외
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">preprocessed_sentence</span><span class="p">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">15</span> <span class="p">:</span> <span class="k">continue</span>
    <span class="n">corpus</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">preprocessed_sentence</span><span class="p">)</span>
<span class="n">corpus</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>
<pre><code class="language-result">['&lt;start&gt; looking for some education &lt;end&gt;',
 '&lt;start&gt; made my way into the night &lt;end&gt;',
 '&lt;start&gt; all that bullshit conversation &lt;end&gt;',
 '&lt;start&gt; i don t even wanna waste your time &lt;end&gt;',
 '&lt;start&gt; let s just say that maybe &lt;end&gt;',
 '&lt;start&gt; you could help me ease my mind &lt;end&gt;',
 '&lt;start&gt; if that s love in your eyes &lt;end&gt;',
 '&lt;start&gt; it s more than enough &lt;end&gt;',
 '&lt;start&gt; had some bad love &lt;end&gt;',
 '&lt;start&gt; ooh , ooh looking for some affirmation &lt;end&gt;']
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
  
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">(</span>
        <span class="n">num_words</span><span class="o">=</span><span class="mi">12000</span><span class="p">,</span> 
        <span class="n">filters</span><span class="o">=</span><span class="s">' '</span><span class="p">,</span>
        <span class="n">oov_token</span><span class="o">=</span><span class="s">"&lt;unk&gt;"</span>
    <span class="p">)</span>
    <span class="n">tokenizer</span><span class="p">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>   
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">sequence</span><span class="p">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'post'</span><span class="p">)</span>  
    
    <span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span><span class="n">tokenizer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">tokenizer</span>

<span class="n">tensor</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-result">[[  2 290  28 ...   0   0   0]
 [  2 219  13 ...   0   0   0]
 [  2  25  15 ...   0   0   0]
 ...
 [  2  44  89 ...   0   0   0]
 [  2   4  24 ...   3   0   0]
 [  2  23   9 ...   3   0   0]] &lt;keras_preprocessing.text.Tokenizer object at 0x7f19fb392410&gt;
(156013, 15)
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">src_input</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  
<span class="n">tgt_input</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>    

<span class="k">print</span><span class="p">(</span><span class="n">src_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">tgt_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<pre><code class="language-result">[   2  290   28   94 4486    3    0    0    0    0    0    0    0    0]
[ 290   28   94 4486    3    0    0    0    0    0    0    0    0    0]
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">src_input</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">src_input</span><span class="p">)</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>

<span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">num_words</span> <span class="o">+</span> <span class="mi">1</span>   
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">enc_train</span><span class="p">,</span> <span class="n">enc_val</span><span class="p">,</span> <span class="n">dec_train</span><span class="p">,</span> <span class="n">dec_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">src_input</span><span class="p">,</span> <span class="n">tgt_input</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">34</span><span class="p">)</span>

<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">enc_train</span><span class="p">,</span> <span class="n">dec_train</span><span class="p">))</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">enc_val</span><span class="p">,</span> <span class="n">dec_val</span><span class="p">))</span>
<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span>
<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TextGenerator</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span> 
        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span> 
        <span class="bp">self</span><span class="p">.</span><span class="n">rnn_1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  
        <span class="bp">self</span><span class="p">.</span><span class="n">rnn_2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rnn_1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rnn_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">out</span>
  
<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TextGenerator</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">num_words</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_size</span> <span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문이다.
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">()</span> 
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
    <span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span> 
<span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">dataset_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span> 
</code></pre></div></div>

<pre><code class="language-result">Epoch 1/10
487/487 [==============================] - 37s 38ms/step - loss: 3.2869 - val_loss: 2.8996
Epoch 2/10
487/487 [==============================] - 18s 37ms/step - loss: 2.7434 - val_loss: 2.6463
Epoch 3/10
487/487 [==============================] - 18s 37ms/step - loss: 2.4323 - val_loss: 2.4659
Epoch 4/10
487/487 [==============================] - 18s 37ms/step - loss: 2.1281 - val_loss: 2.3302
Epoch 5/10
487/487 [==============================] - 18s 37ms/step - loss: 1.8379 - val_loss: 2.2290
Epoch 6/10
487/487 [==============================] - 18s 37ms/step - loss: 1.5790 - val_loss: 2.1656
Epoch 7/10
487/487 [==============================] - 18s 37ms/step - loss: 1.3644 - val_loss: 2.1287
Epoch 8/10
487/487 [==============================] - 18s 37ms/step - loss: 1.2008 - val_loss: 2.1240
Epoch 9/10
487/487 [==============================] - 18s 37ms/step - loss: 1.0897 - val_loss: 2.1351
Epoch 10/10
487/487 [==============================] - 18s 37ms/step - loss: 1.0249 - val_loss: 2.1567
</code></pre>
<pre><code class="language-result">&lt;keras.callbacks.History at 0x7f19fd39af10&gt;
</code></pre>
<p>embedding_size = 512 /</p>

<p>hidden_size = 2048</p>

<ul>
  <li>
    <p>val_loss : 2.16</p>
  </li>
  <li>
    <p>val_loss : 2.15</p>
  </li>
</ul>

<p>embedding_size = 64 /</p>

<p>idden_size  = 1026</p>

<ul>
  <li>val_loss : 2.6</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<pre><code class="language-result">Model: "text_generator"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       multiple                  6144512   
                                                                 
 lstm (LSTM)                 multiple                  20979712  
                                                                 
 lstm_1 (LSTM)               multiple                  33562624  
                                                                 
 dense (Dense)               multiple                  24590049  
                                                                 
=================================================================
Total params: 85,276,897
Trainable params: 85,276,897
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">init_sentence</span><span class="o">=</span><span class="s">"&lt;start&gt;"</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span> <span class="c1">#시작 문자열을 init_sentence 로 받으며 디폴트값은 &lt;start&gt; 를 받는다
</span>    <span class="c1"># 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다
</span>    <span class="n">test_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">init_sentence</span><span class="p">])</span> <span class="c1">#텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환
</span>    <span class="n">test_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">end_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">word_index</span><span class="p">[</span><span class="s">"&lt;end&gt;"</span><span class="p">]</span>

    
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span> <span class="c1">#루프를 돌면서 init_sentence에 단어를 하나씩 생성성
</span>        <span class="n">predict</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_tensor</span><span class="p">)</span> 
        <span class="n">predict_word</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> 
        <span class="n">test_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">test_tensor</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">predict_word</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">predict_word</span><span class="p">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">end_token</span><span class="p">:</span> <span class="k">break</span>
        <span class="k">if</span> <span class="n">test_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">max_len</span><span class="p">:</span> <span class="k">break</span>

    <span class="n">generated</span> <span class="o">=</span> <span class="s">""</span>
    <span class="c1"># tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 
</span>    <span class="k">for</span> <span class="n">word_index</span> <span class="ow">in</span> <span class="n">test_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">numpy</span><span class="p">():</span>
        <span class="n">generated</span> <span class="o">+=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">index_word</span><span class="p">[</span><span class="n">word_index</span><span class="p">]</span> <span class="o">+</span> <span class="s">" "</span>

    <span class="k">return</span> <span class="n">generated</span> <span class="c1">#최종적으로 모델이 생성한 문장을 반환
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generate_text</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">init_sentence</span><span class="o">=</span><span class="s">"&lt;start&gt; l love"</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="c1"># generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성
</span></code></pre></div></div>

<pre><code class="language-result">'&lt;start&gt; l love amour , yeah &lt;end&gt; '
</code></pre>

<h2 id="회고">회고</h2>

<ul>
  <li>
    <p>어려웠던 점 : embedding_size와 hidden_size를 얼마만큼 늘려야 loss를 줄일지가 어려웠다. model.fit의 인자를 batch_size만 추가했다.</p>
  </li>
  <li>
    <p>알아낸 점 및 모호한 점 : model.fit의 shuffle를 추가한 결과랑 아닌 결과랑 차이점이 있는지 궁금하다. 이미 ataset_train.shuffle()을 통해서 model.fit에서 shuffle을 안해도 되는건지 궁금하다. 출력된 문장에 &lt; start &gt;와 &lt; end &gt;, &lt; unk &gt;는 출력을 안하는 방법이 있는지 궁금하다.</p>
  </li>
  <li>
    <p>노력한 점 :  embedding_size와 hidden_size 외에도 다른 model.fit의 인자를 추가하는 방법을 찾기 위해 노력했다. 토큰화 했을 때, 문장 길이가 15개 이하만 train데이터로 하는 과정을 찾아 넣었다.</p>
  </li>
  <li>
    <p>자기다짐 :  embedding_size와 hidden_size을 여러 가지로 해보는 경험이 중요하다고 느꼈다. train과 test 를 split에서 test data의 비율은 고정이고 radomstate를 바꿨을때 val_loss의 값은 크게 차이가 없다는 것을 보았을 때, embedding과 hidden size가 중요하다는 것을 알 수 있었다.</p>
  </li>
</ul>


        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-10-14T00:00:00+09:00">October 14, 2022</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/ai/2022/10/13/Putting-on-a-cat's-beard.html" class="pagination--pager" title="[AIFFEL] CV_고양이수염붙이기
">Previous</a>
    
    
      <a href="/coding/2023/03/03/stack_queue.html" class="pagination--pager" title="스택 큐 우선순위 큐 최대힙 최소힙
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

      </section>
      <footer>
    
    <p>This project is maintained by <a href="https://github.com/darkhairlove">darkhairlove</a></p>
    

<p style="margin-bottom: 0px">
    <small>
        <a href="https://github.com/vaibhavvikas/jekyll-theme-minimalistic">Minimalistic</a> &mdash; Theme by 
        <a href="https://github.com/vaibhavvikas/">vaibhavvikas</a>
    </small>
</p>
</footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
  </body>
</html>
