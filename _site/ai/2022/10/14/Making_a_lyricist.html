<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>[AIFFEL]_작사가만들기</title>
  <meta name="description" content="  ">
  
  <meta name="author" content="Sujin Park">
  <meta name="copyright" content="&copy; Sujin Park 2023">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/monokai-sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="  " />
  <meta property="og:url" content="http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html">
  <meta property="og:site_name" content="AI NOTE" />
  <meta property="og:title" content="[AIFFEL]_작사가만들기" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://localhost:4000/assets/instacode.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="[AIFFEL]_작사가만들기">
  <meta name="twitter:description" content="  ">
  <meta name="twitter:image" content="http://localhost:4000/assets/instacode.png">
  <meta name="twitter:url" content="http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html">
	<link rel="alternate" type="application/rss+xml" title="AI NOTE" href="http://localhost:4000/feed.xml" />
	
	<!-- Tooltips -->
	<script type="text/javascript">
		window.tooltips = []
	</script>
</head>


  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
      
      <img src="/assets/logo.png" alt="AI NOTE">
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
				
	

	
	<li class="nav-link"><a href="/about/">About</a>
	

	

	

	

	

	

	

	
	<li class="nav-link"><a href="/posts/">Posts</a>
	

	
	<li class="nav-link"><a href="/typography/">Typography</a>
	

	

	

	

	

	

	

	

	


      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">

<div class="post-header-container has-cover" style="background-image: url(/assets/instacode.png);">
  <div class="scrim has-cover">
    <header class="post-header">
      <h1 class="title">[AIFFEL]_작사가만들기</h1>
      <p class="info">by <strong>SuJin</strong></p>
    </header>
  </div>
</div>

<div class="wrapper">



<section class="post-meta">
  <div class="post-date">October 14, 2022</div>
  <div class="post-categories">
  in 
    
    <a href="/category/AI">Ai</a>
    
  
  </div>
</section>

<article class="post-content">
  <head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }
  .language-result {
    background : #ffffff00;
    font-size: 0.8rem;
    }
  </style>
</head>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s">'/content/drive'</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-result">Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">txt_file_path</span> <span class="o">=</span> <span class="s">'/content/drive/MyDrive/Colab/AIFFEL/day/lyrics/*'</span> 

<span class="n">txt_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">txt_file_path</span><span class="p">)</span> 

<span class="n">raw_corpus</span> <span class="o">=</span> <span class="p">[]</span> 

<span class="c1"># 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담음.
</span><span class="k">for</span> <span class="n">txt_file</span> <span class="ow">in</span> <span class="n">txt_list</span><span class="p">:</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">txt_file</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">raw</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span> 
        <span class="n">raw_corpus</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">raw</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"데이터 크기:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_corpus</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Examples:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">raw_corpus</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<pre><code class="language-result">데이터 크기: 187088
Examples:
 ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 입력된 문장을
#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다
#     2. 특수문자 양쪽에 공백을 넣고
#     3. 여러개의 공백은 하나의 공백으로 바꿉니다
#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다
#     5. 다시 양쪽 공백을 지웁니다
#     6. 문장 시작에는 &lt;start&gt;, 끝에는 &lt;end&gt;를 추가합니다
</span><span class="k">def</span> <span class="nf">preprocess_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="c1"># 1
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">r"([?.!,¿])"</span><span class="p">,</span> <span class="s">r" \1 "</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="c1"># 2
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">r'[" "]+'</span><span class="p">,</span> <span class="s">" "</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="c1"># 3
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">r"[^a-zA-Z?.!,¿]+"</span><span class="p">,</span> <span class="s">" "</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="c1"># 4
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="c1"># 5
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="s">'&lt;start&gt; '</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="s">' &lt;end&gt;'</span> <span class="c1"># 6
</span>    <span class="k">return</span> <span class="n">sentence</span>
</code></pre></div></div>

<h2 id="정제된-문자">정제된 문자</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corpus</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">raw_corpus</span><span class="p">:</span>
    <span class="c1"># 원하지 않는 문장은 건너뜀.
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span> <span class="k">continue</span>
    <span class="k">if</span> <span class="n">sentence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s">":"</span><span class="p">:</span> <span class="k">continue</span>
    <span class="n">preprocessed_sentence</span> <span class="o">=</span> <span class="n">preprocess_sentence</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="c1"># 토큰의 개수가 15개를 넘어가는 문장 제외
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">preprocessed_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">15</span> <span class="p">:</span> <span class="k">continue</span>
    <span class="n">corpus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">preprocessed_sentence</span><span class="p">)</span>
<span class="n">corpus</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>
<pre><code class="language-result">['&lt;start&gt; looking for some education &lt;end&gt;',
 '&lt;start&gt; made my way into the night &lt;end&gt;',
 '&lt;start&gt; all that bullshit conversation &lt;end&gt;',
 '&lt;start&gt; i don t even wanna waste your time &lt;end&gt;',
 '&lt;start&gt; let s just say that maybe &lt;end&gt;',
 '&lt;start&gt; you could help me ease my mind &lt;end&gt;',
 '&lt;start&gt; if that s love in your eyes &lt;end&gt;',
 '&lt;start&gt; it s more than enough &lt;end&gt;',
 '&lt;start&gt; had some bad love &lt;end&gt;',
 '&lt;start&gt; ooh , ooh looking for some affirmation &lt;end&gt;']
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
  
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">Tokenizer</span><span class="p">(</span>
        <span class="n">num_words</span><span class="o">=</span><span class="mi">12000</span><span class="p">,</span> 
        <span class="n">filters</span><span class="o">=</span><span class="s">' '</span><span class="p">,</span>
        <span class="n">oov_token</span><span class="o">=</span><span class="s">"&lt;unk&gt;"</span>
    <span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>   
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'post'</span><span class="p">)</span>  
    
    <span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span><span class="n">tokenizer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">tokenizer</span>

<span class="n">tensor</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-result">[[  2 290  28 ...   0   0   0]
 [  2 219  13 ...   0   0   0]
 [  2  25  15 ...   0   0   0]
 ...
 [  2  44  89 ...   0   0   0]
 [  2   4  24 ...   3   0   0]
 [  2  23   9 ...   3   0   0]] &lt;keras_preprocessing.text.Tokenizer object at 0x7f19fb392410&gt;
(156013, 15)
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">src_input</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  
<span class="n">tgt_input</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>    

<span class="k">print</span><span class="p">(</span><span class="n">src_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">tgt_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<pre><code class="language-result">[   2  290   28   94 4486    3    0    0    0    0    0    0    0    0]
[ 290   28   94 4486    3    0    0    0    0    0    0    0    0    0]
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">src_input</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">src_input</span><span class="p">)</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>

<span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">num_words</span> <span class="o">+</span> <span class="mi">1</span>   
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">enc_train</span><span class="p">,</span> <span class="n">enc_val</span><span class="p">,</span> <span class="n">dec_train</span><span class="p">,</span> <span class="n">dec_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">src_input</span><span class="p">,</span> <span class="n">tgt_input</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">34</span><span class="p">)</span>

<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">enc_train</span><span class="p">,</span> <span class="n">dec_train</span><span class="p">))</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span>
<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">dataset_train</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">enc_val</span><span class="p">,</span> <span class="n">dec_val</span><span class="p">))</span>
<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span>
<span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TextGenerator</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">out</span>
  
<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TextGenerator</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">num_words</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embedding_size</span> <span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="c1"># tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문이다.
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> 
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
    <span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span> 
<span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">dataset_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span> 
</code></pre></div></div>

<pre><code class="language-result">Epoch 1/10
487/487 [==============================] - 37s 38ms/step - loss: 3.2869 - val_loss: 2.8996
Epoch 2/10
487/487 [==============================] - 18s 37ms/step - loss: 2.7434 - val_loss: 2.6463
Epoch 3/10
487/487 [==============================] - 18s 37ms/step - loss: 2.4323 - val_loss: 2.4659
Epoch 4/10
487/487 [==============================] - 18s 37ms/step - loss: 2.1281 - val_loss: 2.3302
Epoch 5/10
487/487 [==============================] - 18s 37ms/step - loss: 1.8379 - val_loss: 2.2290
Epoch 6/10
487/487 [==============================] - 18s 37ms/step - loss: 1.5790 - val_loss: 2.1656
Epoch 7/10
487/487 [==============================] - 18s 37ms/step - loss: 1.3644 - val_loss: 2.1287
Epoch 8/10
487/487 [==============================] - 18s 37ms/step - loss: 1.2008 - val_loss: 2.1240
Epoch 9/10
487/487 [==============================] - 18s 37ms/step - loss: 1.0897 - val_loss: 2.1351
Epoch 10/10
487/487 [==============================] - 18s 37ms/step - loss: 1.0249 - val_loss: 2.1567
</code></pre>
<pre><code class="language-result">&lt;keras.callbacks.History at 0x7f19fd39af10&gt;
</code></pre>
<p>embedding_size = 512 /</p>

<p>hidden_size = 2048</p>

<ul>
  <li>
    <p>val_loss : 2.16</p>
  </li>
  <li>
    <p>val_loss : 2.15</p>
  </li>
</ul>

<p>embedding_size = 64 /</p>

<p>idden_size  = 1026</p>

<ul>
  <li>val_loss : 2.6</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<pre><code class="language-result">Model: "text_generator"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       multiple                  6144512   
                                                                 
 lstm (LSTM)                 multiple                  20979712  
                                                                 
 lstm_1 (LSTM)               multiple                  33562624  
                                                                 
 dense (Dense)               multiple                  24590049  
                                                                 
=================================================================
Total params: 85,276,897
Trainable params: 85,276,897
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">init_sentence</span><span class="o">=</span><span class="s">"&lt;start&gt;"</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span> <span class="c1">#시작 문자열을 init_sentence 로 받으며 디폴트값은 &lt;start&gt; 를 받는다
</span>    <span class="c1"># 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다
</span>    <span class="n">test_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">init_sentence</span><span class="p">])</span> <span class="c1">#텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환
</span>    <span class="n">test_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">end_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="s">"&lt;end&gt;"</span><span class="p">]</span>

    
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span> <span class="c1">#루프를 돌면서 init_sentence에 단어를 하나씩 생성성
</span>        <span class="n">predict</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_tensor</span><span class="p">)</span> 
        <span class="n">predict_word</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> 
        <span class="n">test_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">test_tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">predict_word</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">predict_word</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">end_token</span><span class="p">:</span> <span class="k">break</span>
        <span class="k">if</span> <span class="n">test_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">max_len</span><span class="p">:</span> <span class="k">break</span>

    <span class="n">generated</span> <span class="o">=</span> <span class="s">""</span>
    <span class="c1"># tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 
</span>    <span class="k">for</span> <span class="n">word_index</span> <span class="ow">in</span> <span class="n">test_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">():</span>
        <span class="n">generated</span> <span class="o">+=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">index_word</span><span class="p">[</span><span class="n">word_index</span><span class="p">]</span> <span class="o">+</span> <span class="s">" "</span>

    <span class="k">return</span> <span class="n">generated</span> <span class="c1">#최종적으로 모델이 생성한 문장을 반환
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generate_text</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">init_sentence</span><span class="o">=</span><span class="s">"&lt;start&gt; l love"</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="c1"># generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성
</span></code></pre></div></div>

<pre><code class="language-result">'&lt;start&gt; l love amour , yeah &lt;end&gt; '
</code></pre>

<h2 id="회고">회고</h2>

<ul>
  <li>
    <p>어려웠던 점 : embedding_size와 hidden_size를 얼마만큼 늘려야 loss를 줄일지가 어려웠다. model.fit의 인자를 batch_size만 추가했다.</p>
  </li>
  <li>
    <p>알아낸 점 및 모호한 점 : model.fit의 shuffle를 추가한 결과랑 아닌 결과랑 차이점이 있는지 궁금하다. 이미 ataset_train.shuffle()을 통해서 model.fit에서 shuffle을 안해도 되는건지 궁금하다. 출력된 문장에 &lt; start &gt;와 &lt; end &gt;, &lt; unk &gt;는 출력을 안하는 방법이 있는지 궁금하다.</p>
  </li>
  <li>
    <p>노력한 점 :  embedding_size와 hidden_size 외에도 다른 model.fit의 인자를 추가하는 방법을 찾기 위해 노력했다. 토큰화 했을 때, 문장 길이가 15개 이하만 train데이터로 하는 과정을 찾아 넣었다.</p>
  </li>
  <li>
    <p>자기다짐 :  embedding_size와 hidden_size을 여러 가지로 해보는 경험이 중요하다고 느꼈다. train과 test 를 split에서 test data의 비율은 고정이고 radomstate를 바꿨을때 val_loss의 값은 크게 차이가 없다는 것을 보았을 때, embedding과 hidden size가 중요하다는 것을 알 수 있었다.</p>
  </li>
</ul>


</article>



<section class="tags">
  <strong>Tags:</strong> <a href="/tag/Python">Python</a>,&nbsp;<a href="/tag/NLP">NLP</a>
</section>



<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>Share: </span>
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
      <a href="//www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fai%2F2022%2F10%2F14%2FMaking_a_lyricist.html"
        onclick="window.open(this.href, 'linkedin-share', 'width=550,height=255');return false;">
        <i class="fa fa-linkedin-square fa-lg"></i>
      </a>
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
      <a href="//www.pinterest.com/pin/create/button/?description=%5BAIFFEL%5D_%EC%9E%91%EC%82%AC%EA%B0%80%EB%A7%8C%EB%93%A4%EA%B8%B0&url=http%3A%2F%2Flocalhost%3A4000%2Fai%2F2022%2F10%2F14%2FMaking_a_lyricist.html&media=http://localhost:4000/assets/instacode.png"
        onclick="window.open(this.href, 'pinterest-share', 'width=550,height=255');return false;">
        <i class="fa fa-pinterest-square fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
      <a href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent('http://localhost:4000/ai/2022/10/14/Making_a_lyricist.html') + '&title=[AIFFEL]_작사가만들기'; return false">
        <i class="fa fa-reddit-square fa-lg"></i>
      </a>
    
    
  
    
    
    
    
    
    
    
    
  
</section>




</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">AI NOTE</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <ul class="pages">
				
	

	
	<li class="nav-link"><a href="/about/">About</a>
	

	

	

	

	

	

	

	
	<li class="nav-link"><a href="/posts/">Posts</a>
	

	
	<li class="nav-link"><a href="/typography/">Typography</a>
	

	

	

	

	

	

	

	

	


      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:suqkr12@gmail.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">suqkr12@gmail.com</span>
          </a>
        </li>

        
          
          <li>
            <a href="https://github.com/darkhairlove" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">Sujin Park</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://www.linkedin.com/in/sujin-park-data-darkhair/" title="Connect with me on LinkedIn">
              <i class="fa fa-linkedin"></i>
              <span class="username">Sujin Park</span>
            </a>
          </li>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        

      </ul>
    </div>

    <div class="site-signature">
      <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
      <p class="text">studying AI and Python
</p>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-3.4.1.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.1/js/lightbox.min.js"></script>
<script src="//unpkg.com/popper.js@1"></script>
<script src="//unpkg.com/tippy.js@5"></script>

<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();

  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });

	// Enable tooltips via Tippy.js
	if (Array.isArray(window.tooltips)) {
		window.tooltips.forEach(function(tooltip) {
			var selector = tooltip[0];
			var config = tooltip[1];
			tippy(selector, config);
		})
	}
});

</script>




<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'G-YMLDH27YFB', 'auto');
  ga('send', 'pageview', {
    'page': '/ai/2022/10/14/Making_a_lyricist.html',
    'title': '[AIFFEL]_작사가만들기'
  });
</script>



  </body>

</html>
