---
layout: single
title:  "작사가_만들기-title2"
categories: AI
tag: [python, aiffel, ai]
toc: true
author_profile: false
---


## 회고

- 어려웠던 점 : embedding_size와 hidden_size를 얼마만큼 늘려야 loss를 줄일지가 어려웠다. model.fit의 인자를 batch_size만 추가했다.

- 알아낸 점 및 모호한 점 : model.fit의 shuffle를 추가한 결과랑 아닌 결과랑 차이점이 있는지 궁금하다. 이미 ataset_train.shuffle()을 통해서 model.fit에서 shuffle을 안해도 되는건지 궁금하다. 출력된 문장에 < start >와 < end >, < unk >는 출력을 안하는 방법이 있는지 궁금하다.

- 노력한 점 :  embedding_size와 hidden_size 외에도 다른 model.fit의 인자를 추가하는 방법을 찾기 위해 노력했다. 토큰화 했을 때, 문장 길이가 15개 이하만 train데이터로 하는 과정을 찾아 넣었다.

- 자기다짐 :  embedding_size와 hidden_size을 여러 가지로 해보는 경험이 중요하다고 느꼈다. train과 test 를 split에서 test data의 비율은 고정이고 radomstate를 바꿨을때 val_loss의 값은 크게 차이가 없다는 것을 보았을 때, embedding과 hidden size가 중요하다는 것을 알 수 있었다. 

