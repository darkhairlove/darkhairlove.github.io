---
layout: post
title: "[Review]-TODS와 End-to-End GPT-2 Paper"
date: 2023-03-20 08:43:59
author: Su Jin
categories: NLP
tags: [Review]
---

# TODS 란?

- Task-Oriented Dialogue System으로 open domain과 달리 task를 가지고 사용자가 말한 문제를 해결하는 것.
    - 반대로, Open domain은 유저가 어떤 말을 걸어도 알맞은 대답을 하는것 (Chit-Chat)

![Untitled](/assets/img/content/TOD/Untitled.png)

Intent 와 slot value를 계속 tracking, Multi-turn 형식으로 KB(Knowledge Base)에 있는 정보를 가져오는 형태, NLG로 대화가 생성

### 문제

- Data Efficiency : open domain보다 어려운 데이터 수집, Low resource training의 필요성.
- Multi-turn Dynamics : 여러 Turn의 발화 속에서 자연스럽게 사용자의 목적을 달성해야 함.
- Ontology Intergration : 다양한 Task에도 활용이 가능한 모델 (KB를 다양하게 만들어야 함.)
- Evaluation : 더 효율적인 평가 방법을 만들어야 함.

# 구성

- **파이프라인(Pipeline)또는 모듈러(Modular) 시스템.**
    
    ![Untitled](/assets/img/content/TOD/Untitled_1.png)
    
    - **Natural Language Understanding(NLU)** : 도메인(domain), 의도(intent), 개체명(entity)를 추출.
        - ex) ‘내일 날씨가 어때?’ → Intent : ‘날씨’, entity : ‘내일’
    - **Dialog State Tracking(DST)** : NLU에서 들어온 도메인, 의도, 객체명을 기반으로 대화의 상태를 업데이트하고 이전 대화에서 추적하고 저장.
        - Ontology based : 미리 상황에 맞는 dialogue ontology 구축, 모든 경우를 고려할 수 없어. unseen domain, slot, value 가 주어졌을 때, 대답할 수 없음.
        - Open vocabulary based : Input에 따라 대답을 즉각적 생성. 실제 대화에 더 적합하다.
    - **Policy** : DST에서 받은 내용으로 현재 대화 상태와 목적에 고려하여 dialogue action을 선택
        - 질문하기, 답변하기, 정보 제공하기, 정보 요청하기 등을 할 수 있다.
        - 강화학습을 기반으로 Policy를 학습할 수 있다. ex)GDPL을 사용하여 reward 함수에 활용.
            
            현재 상태에서 가장 높은 보상을 받는 것을 선택.
            
    - **Natural Language Generation(NLG)** : Dialogue Action을 자연어로 바꾸는 과정.
        - Template-based(rule-based): 사전에 정의된 템플릿을 사용
        - Data-driven : seq2seq, transformer와 같은 딥러닝 모델을 사용하여 대답을 생성
- **End-to-End 시스템** : 위 모듈을 하나의 모델로 통합하여 학습과 실행.
    - ex) DST, Policy, NLG를 거치지 않고 대화의 도메인, 의도, 개체명을 직접 예측하여 문장 생성
    - [SimpleTOD](https://blog.salesforceairesearch.com/simpletod/), [Topic Model](https://www.researchgate.net/publication/363482625_Topic_Model_for_Personalized_End-to-End_Task-Oriented_Dialogue) 등이 있다.
    - 하지만 대화의 맥락과 사용자 요구를 완전히 이해할 수 없을 수 있다.
- **조합(joint) 시스템**
    - Pipeline 4가지 중 일부를 결합한 방식을 혼합한 방식
    - word-level DST는 NLU와 DST를 결합한 방식이고, Word-level Policy는 Policy와 NLG를 결합한 시스템
        
        ![[[2005.07362] Is Your Goal-Oriented Dialog Model Performing Really Well? Empirical Analysis of System-wise Evaluation (arxiv.org)](https://arxiv.org/abs/2005.07362)](../assets/img/content/TOD/Untitled_2.png)
        
        [[2005.07362] Is Your Goal-Oriented Dialog Model Performing Really Well? Empirical Analysis of System-wise Evaluation (arxiv.org)](https://arxiv.org/abs/2005.07362)
        

## 평가방식

### Automatic Evaluation

- NLU : Slot F1-score, Intent Accuracy
- DST : Slot Accuracy, Join state Accuracy
    - 예를 들어, 슬롯 기반 대화 시스템이 음식 주문에 대한 대화를 처리한다고 가정. 
    사용자가 "저녁으로 피자 주문할게요"라는 발화를 하면, 시스템은 "어떤 종류의 피자를 주문하시겠어요?"라는 응답을 생성합니다. 이때, 시스템은 "피자"라는 슬롯 정보를 추출.
        
        이후 사용자가 "페퍼로니 피자 주문할게요"라는 발화를 하면, 시스템은 "페퍼로니 피자를 주문하시겠어요?"라는 응답을 생성하고, "피자 종류" 슬롯 정보를 "페퍼로니"로 업데이트.
        
        join accuracy는 이 대화 턴에서 시스템이 사용자 발화를 올바르게 이해하고, 적절한 시스템 응답을 생성하여 대화의 일관성과 흐름을 유지하는 비율을 나타냅니다. 예를 들어, 시스템이 "어떤 종류의 피자를 주문하시겠어요?" 대신 "저녁으로 어떤 음식을 드시겠어요?"라는 응답을 생성하면 join accuracy는 낮아집니다.
        
        slot accuracy는 이 대화 턴에서 시스템이 "피자 종류" 슬롯 정보를 올바르게 추출하여 "페퍼로니"로 업데이트하는 비율을 나타냅니다. 예를 들어, 시스템이 "토마토"나 "치즈"와 같은 잘못된 정보를 추출하면 slot accuracy는 낮아집니다.
        
- Policy : Inform rate(F1-score), Match rate, Task success rate
- NLG : BLEU, Perplexity

### Simulated Evaluation

- 유저의 행동을 따라하는 시뮬레이터에 따른 평가
- Rule-based or can be learned data driven
- Task success rate, Dialogue length, Average rewards
    - 시스템을 End-to-End로 평가할 수 있음
    - 추론할 때 Multi-turn interaction을 평가할 수 있음

### Human Evaluation

- Task success rate, Irrelevant turn rate, Redundant turn rate, User satisfaction score
- Direct(모델과 직접 평가) vs. Indirect(모델과 유저의 내용을 보고 평가)

## 데이터 셋 구성

1. 기계 - 기계 : 사전에 만든 탬플릿에 맞게 생성되어 안정적이다 하지만 noisy condition에 대해 고려 되지 않았다.
2. 사람 - 기계 : 초기 시스템이 수집된 데이터에 추가적인 편향을 도입하여 훈련과 테스트 세트 간의 불일치를 만들 수 있다. 자연스러운 데이터는 아니다.
3. 사람 - 사람 : 사람간의 대화이지만 대화의 목적이 없기 때문에  일관되고 다양하지 못하고 평가하기 어렵다.

개선하기 위해 : 인터페이스에 사용자가 입력하고 많은 인력을 사용.

---

# MultiWOZ

기존 데이터 셋의 종류는 3가지로

1. 기계 - 기계 : 사전에 만든 탬플릿에 맞게 생성되어 안정적이다 하지만 noisy condition에 대해 고려 되지 않았다.
2. 사람 - 기계 : 초기 시스템이 수집된 데이터에 추가적인 편향을 도입하여 훈련과 테스트 세트 간의 불일치를 만들 수 있다. 자연스러운 데이터는 아니다.
3. 사람 - 사람 : 사람간의 대화이지만 대화의 목적이 없기 때문에  일관되고 다양하지 못하고 평가하기 어렵다.

개선하기 위해 : 인터페이스에 사용자가 입력하고 많은 인력을 사용.

### 수집 방법

- Ontology : 백엔드 데이터베이스의 구조화된 representation. 모든 entity attribute Slot과 각 슬롯에 대한 모든 가능한 값.
- slot : informable, requestable으로 나눠져 있다.
- informable : 사용자가 검색할 수 있는 내용들 (ex, 지역, 가격범위)
- requestable : 사용자가 entity에 대해 요청할 수 있는 내용들 (ex, 전화 번호)
- User side : 유저가 입력한 대답
- system side : DB에 있는 대답
- Annotataion of Dialogue Acts : 대답에 대한 주석 `inform(domain=hotel,price=expensive)`과 같은 것, intent inform 인 경우 사용자가 싼 hotel을 찾는다는 것을 system이 알고 있다.
    - MTurk website set-up
    - 주석 처리 하는 과정
        
        ![Untitled](/assets/img/content/TOD/Untitled3.png)
        
        ![Untitled](/assets/img/content/TOD/Untitled4.png)
        
        ![Untitled](/assets/img/content/TOD/Untitled5.png)
        
- Fleiss’ kappa metric 을 단일 대화에 사용하면서 데이터를 수집. → 0.704로 높았지만, 주석처리를 잘 못한 경우가 보였다.
    - 다중 평가자들이 다수의 항목에 대해 얼마나 일치하는지 측정하는 통계적 지표
    - 각 평가자들이 각 항목에 대해 얼마나 동의하는지 계산하고 전체 평가자들 간의 일치도를 평균화하여 계산
- 결국 Fleiss’ Kappa 값이 0.884로 높였지만, trun이 291이었다.

### MultiWOZ의 대화 코퍼스

- 7개의 도메인 - Attraction, Hospital, Police, Hotel, Restaurant, Taxi, Train
**하나의 대화가 여러 도메인으로 연결되어 있다. 대화의 길이와 복잡성이 다르다. → 자연스러운 대화 연결로 시나리오를 만들 수 있다.

### 데이터 통계

- 10438개의 대화가 수집되었다.
    
    ![스크린샷 2023-03-19 오후 2.30.54.png](/assets/img/content/TOD/21.png)
    
    단일 도메인과 멀티 도메인의 길이 분포
    
- 대화의 약 70%는 코퍼스의 복잡성을 보여주는 10턴 이상을 가지고 있다.
- 단일 도메인은 평균 8.93 turn, 멀티 도메인은 평균 15.39 turn을 가지고 있다.
- 총 turn 수는 115,434입니다.
    
    ![스크린샷 2023-03-19 오후 2.31.11.png](/assets/img/content/TOD/20.png)
    
    user와 system(wizards)의 문장 길이의 분포
    
- user의 평균 길이는 11.75, system의 평균 길이는 15.12 즉 system이 더 길다.
    
    ![스크린샷 2023-03-19 오후 2.44.03.png](/assets/img/content/TOD/19.png)
    
    코퍼스에 달린 dialogue act의 분포
    
    ![스크린샷 2023-03-19 오후 2.47.17.png](/assets/img/content/TOD/18.png)
    
    각 trun당 act의 개수(한 turn에서 어느정도 act을 행하는지)
    
    한 번 turn에서 act한 비율이 40% 정도
    
- 1개의 act일 경우 높은 turn의 비율을 보여준다.
- 강화학습에 사용에 적용할 수 있다?
    
    ![스크린샷 2023-03-19 오후 2.53.46.png](/assets/img/content/TOD/17.png)
    
- 대화 중에 매우 짧은 질문, 짧은 대화 또는 누락된 단일 turn을 자동적으로 발견하는 것을 제한으로 추가함.→수정하거나 삭제함

### 구조

- 단일 도메인(single-domain) : 3,406개 (예약을 포함하는 대화)
- 멀티 도메인(multi-domain) : 7,032개 (2-5개의 도메인을 가지고 있는 대화)
- test와 validation set을 목적을 이룬 대화 내용만 포함시켰다. (이유 - 끝나지 않은 대화가 포함된 경우가 있기 때문에)

### 다른 코퍼스 구조 비교

![스크린샷 2023-03-19 오후 3.08.50.png](/assets/img/content/TOD/16.png)

총 대화 수, turn 전체 수, 전체 토큰 수, 턴 당 평균 토큰 수, 특별한 토큰 총수 다른 것에 비해 뛰어나다.

## MultiWOZ의 Benchmark

### Dialogue State Tracking (DST)

- belief state : Dialogue와 같은 말로 대화의 상태
- ontology : slot과 value을 가지고 있는 것.

![스크린샷 2023-03-19 오후 3.30.58.png](/assets/img/content/TOD/1.png)

- Multi-WOZ에서 sub-domain인 레스토랑만 사용하여 전체 정확도와 목표를 확인했다.
- 이전 WOZ 2.0보다 점수가 떨어졌다. 이유는 대화의 길이가 더 길어지고 풍성하기 때문에 Multi-WOZ가 까다로움을 보여준다.

### **Dialogue-Context-to-Text Generation**

대화의 맥락을 고려하여 텍스트를 생성하는 것, 대화에서 이전 발화와 현재 발화를 모두 고려하여 응답을 생성

- end-to-end을 적용할 수 있다.
- Belief tracking에 있어서 Dialogue management 와 response generation 을 독립으로 보기 위해  baseline neural response generation model 사용 : oracle belief-state
- seq-to-seq model : 디코더에서 단어 선택을 위한 추가 기능으로 belief tracking과 개별 DB component 접근을 하여 보강한다.
- belief tracker는 pre-trained 되어있고, dialogue state의 주석은 oracle tracker을 사용되었다.
    
    ![스크린샷 2023-03-19 오후 4.07.30.png](/assets/img/content/TOD/2.png)
    
    구조도.
    
- train, eval : 평가 지표로 3가지 - 정보률, 성공율, 유창성을 보기 위해 BLEU를 사용
- Cam676과 비교
    
    ![스크린샷 2023-03-19 오후 4.27.49.png](/assets/img/content/TOD/3.png)
    
    Cam676 : bidirectional GRU cell
    
    MultiWOZ : LSTM cell (인코더 - 디코더), attention을 이용
    

- MultiWOZ의 BLEU 점수가 낮은 이유가 다양한 언어 표현으로 인해 발생되는 것.
- MultiWOZ에 attention을 추가한 것이 1%정도 올라감. 하지만 Cam676보다는 점수가 떨어짐.
- MultiWOZ는 2가지 도메인에 걸쳐있기 때문에 Cam676의 성공률이 떨어지지 않고 향상할 수 있던 이유.

### **Dialogue-Act-to-Text Generation**

발화의 의도와 목적을 파악하여 텍스트를 생성하는 것, 대화에서 각 발화가 어떤 목적을 가지고 있는지를 이해하고, 그에 맞는 응답을 생성하는 것.

- SFX와 비교
    
    ![스크린샷 2023-03-19 오후 4.43.42.png](/assets/img/content/TOD/4.png)
    
- SFX 사용한 이유 : 언어 생성 작업을 위해 수집된 데이터 세트의 어려움을 확인하기 위해
- 두 데이터 세트에 대해 제안한 동일한 Semantically Conditioned Long Short-term Memory 네트워크(SC-LSTM)로 train
- 두 corpora 차이를 위해 metric을 proxy 사용 - proxy란 문법적으로 정확한 문장의 비율, 혹은 특정한 태스크에서 모델의 성능 평가.
- SER(slot error rate)와 BLEU로 보았는데, MultiWOZ의 점수가 낮다. 그 이유는 SFX에 있는 레스토랑 데이터가 어렵다는 의미. 또한, 대화 turn에서 두 가지의 domain이 연결되어 있어 성능이 나빠질 가능성이 있다.

## 결론

- human-human 대화의 대규모, 언어적으로 풍부한 코퍼스를 수집하기 위한 크라우드 소싱을 기반으로 하는 데이터 수집 파이프라인에 대한 내용
- end-to-end 모델링에서 연구에 도움이 되길 바람.

---

# End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2

- 목적 지향 대화 시스템이란, 대화 흐름을 추적하고 사용자 목적을 충족시키기 위해 다양한 상황에서 효과적인 대화를 수행하도록 최적화하는 것.
- 어려운점 두 가지
    - 기존 방식은 각 모듈을 개별적으로 최적화하는 파이프라인 모듈 구조를 사용하는 것으로 전체 시스템의 성능 향상을 보장하지 않을 수 있다.
    - 반면, monolithic neural architecture를 가진 end-to-end 대화 시스템은 전체 코퍼스에서 사용 가능한 주석을 고려하지 않고 입력-출력 문장만 사용하여 학습되므로, 외부 시스템과 통합되거나 시스템이 특정 응답을 생성한 이유를 설명하기 어렵습니다.
- 두 가지 문제를 해결하기 위해 end-to-end neural architecture
    1. DST : Dialogue state 예측을 통한
    2. POL : system action 예측을 통한
    3. dialogue state 와 system action을 외부 데이터베이스에서 해당 레코드를 검색
    4. NLG : system response 예측을 통한
- system respone 생성 뿐만 아니라 dialogue state와 system action을 생성.
- MultiWOZ 데이터셋을 이용함. (이유는 코퍼스에 제공된 대화 상태와 시스템 행동의 주석을 활용하기 위해서.)
- ConvLab 사용하여 평가 - automatic(user simulatior), human evaluation(DSTC8에서 함.)
- Dialogue State Tracking 와 Dialogue-Context-to-Text Generation tasks에 대해 장점이 있다.
    1. 전통적인 대화 관리 파이프라인을 따르도록 훈련되며, monolithic neural model 보다 외부 시스템과 함께 쉽게 통합할 수 있다.
    2. 단순한 그라디언트 하강으로 end-to-end 방식.
    3. 사전 훈련된 언어 모델인 GPT-2를 활용.

### **End-to-end Multi-Domain Task-Completion Task**

### dataset : MultiWOZ

![스크린샷 2023-03-19 오후 6.12.05.png](/assets/img/content/TOD/5.png)

- 각 대화에 ‘Goal’, ‘Database’, ‘Dialogue turns’ 이 있다.
- Goal : 도메인과 slot으로 정의됨.
- Informable slot : 사용자의 제약 (사용자가 물어본)
- Requestable slot : 사용자가 추가로 요구할 수 있는 것
- Book slot : system이 사용자한테 장소를 추천하여 예약할 때 사용

### ConvLab

- MILU for NLU, a rule-based policy, template-based NLG 시뮬레이터를 제공한다.
    - ConvLab은 대화 시스템 연구를 위한 종합적인 플랫폼으로, 대화 시스템의 다양한 구성 요소를 포괄하고 있습니다. 다양한 대화 시스템 모델링과 학습 방법을 지원하며, 다양한 대화 데이터셋을 활용하여 대화 시스템의 성능을 평가하는 곳.
- (1) 사용자가 알려주는 것을 추적하고
(2) 사용자가 요청한 것을 알리고 
(3) 추적된 정보를 기반으로 외부 데이터베이스를 사용하여 적절한 예약을 하는지 여부를 평가
- 사용자 시뮬레이터와 평가자는 매우 정교하지만, 인간만큼 완벽하지는 않다. 
따라서, DSTC8에서 human crowd-worker도 평가되었다.

### **End-to-End Neural Pipeline for Goal-Oriented Dialogue System**

- MultiWOZ 데이터 세트의 delexicalized 버전에서 미세 조정된 GPT-2 모델, 데이터베이스 쿼리 모듈.
    
    ![스크린샷 2023-03-19 오후 6.27.38.png](/assets/img/content/TOD/6.png)
    
    pre-trained 한 GPT-2 모델과 fine-tune을 하였다.
    

### 과정

1. dialogue history에서 최근 domain과 dialogue state를 예측.
2. dialogue history 와 dialogue state를 가진 system action의 delexicalized token을 예측.
3. system action(예: 'inform', 'book')이 데이터베이스로부터 외부 정보를 필요로 하는 경우, query module은 후보를 검색하여 그 중 하나를 반환.
4. Empty Query Results를 감지할 때 현재 system action을 업데이트.
5. dialogue history, dialogue state, system action을 가진 system respons의 delexicalized token을 생성.
6. Query 결과를 system에서 delexicalized tokens 업데이트.

### Input

![스크린샷 2023-03-19 오후 6.40.50.png](/assets/img/content/TOD/15.png)

- Metadata : Dialogue state
- dialog_act : System action
- GPT-2을 사용하기 위해서는 단어 토큰으로 바꿔야 한다.
- delimiter token으로 `<usr>, <sys>, <ds>, <sa>` 사용
각각 user utterance, system response, dialogur state, system action
- special token으로 `<nm>, <dc>`는 각각 not mentioned, don’t care
- 따라서 아래와 같이 input embedding으로 token embedding, speaker embedding, positional embedding 구성 됨.

![스크린샷 2023-03-19 오후 6.46.30.png](/assets/img/content/TOD/13.png)

### **Delexicalization**

- requestable slot을 [DOMAIN_SLOTNAME]과 같이 바꾸는 것을 Delexicalization라고 함.
- [DOMAIN_SLOTNAME]과 같이 system response의 delexicalization을 학습하고, delexicalization token들을 나중에 실제 정보인 DB에서 가져온다.

### **Training Objective**

- weighted sum을 optimize하기 위해 LM(language modeling)과 NC(next-utterance classification)
- LM : previous word-token으로 next word-token의 likelihood을 계산하는 목적
    
    ![스크린샷 2023-03-20 오전 1.03.21.png](/assets/img/content/TOD/12.png)
    
- NC : 진짜와 가짜를 구분하기 위해
- linear classifier GPT-2의 디코더 블록의 마지막 hidden state를 입력으로 취하고 softmax layer를 통과하여 class probability를 계산
- cross-entropy loss를 사용해 class probability와 correct label 차이를 계산
- $W = (w_1,… w_n)$ : 주어진 word sequence, $\alpha_{LM}, \alpha_{NC}$ : hyper-parameter

![스크린샷 2023-03-20 오전 1.16.50.png](/assets/img/content/TOD/11.png)

### Decoding Strategy

- Greedy decoding, beam search
- Greedy decoding : 각 위치에서 가장 높은 확률을 가진 토큰만 고려하기 때문에, 전반적으로 정확도가 떨어질 수 있다.
- Beem search decoding : 대화와 같은 높은 entorpy 자연어 생성에 적합하지 않다.
- sampling-based decoding  : top-k sampling 과 top-p sampling 함.

### Empty Query Result

- intent [*Empty-Query-Result*]에 해당하는 문장을 생성함. → <EQR> 토큰으로 만든 후 GPT-2가 문장을 생성

## **Experimental Setting**

### **Training Details**

- GPT2-small(124M parameter) : 12개 decoder block과 pre-trained weights, 
sub-word : GPT2Tokenizer, 4epochs, batch size : 2, MultiWOZ training dataset
Adam optimizer : $\beta_{1}$ = 0.9, $\beta_{2}$=0.999, learning rate = 6.25e-5, $\alpha_{LM} : 2.0, \alpha_{NC} :1.0$

### Evaluation Metrics

- Automatic evaluation (user simulator) : Success Rate, Book Rate, Return, Turns, Precision, Recall, F1
- Human evaluation(crowd-workers) :  Success Rate, Language Understanding Score, Response Appropriateness Score, Turns
    - Success Rate : requestable slot이 올바르게 맞는지, book success가 성공적으로 이뤘는지.
    - Book success :  informable slot의 모든 정보가 맞을 때, 이뤄지는 것으로 Book rate에 sub-evaluation으로 해당.
    - Return : 만약 성공한 task 라면 -Turns + 2*max_turn 이고 아니면 -Turns +(-1)*max_turn으로 계산됨. max_turn은 제한된 최대 turn 수.
    - Precision, Recall, F1 : requestable slot을 채워지는 것을 평가하는데 쓰임.
    - human evaluation : DSTC8 organizers들이 language understanding와 response appropriateness을 보고 5 point을 주면서 자연스러운 답변인지 평가

## Results

### Automatic Evaluation

![스크린샷 2023-03-20 오후 10.06.56.png](/assets/img/content/TOD/10.png)

- intent 인식을 잘못하여 성능이 떨어진 부분이 있다.
- 이를 개선하기 위해 강화학습을 사용하여 intent 인식을 실패하는 것을 피할 수 있다고 생각한다.

### Human Evaluation

![스크린샷 2023-03-20 오후 10.15.08.png](/assets/img/content/TOD/9.png)

- top-p sampling (p=0.8) 으로 1위를 했다.

### Attention Weights

![스크린샷 2023-03-20 오후 10.19.55.png](/assets/img/content/TOD/8.png)

- ‘*I’m looking for modern European food*’ → dialogue state <area> <nm> 생성
- system action에서 <restaurant-nooffer>일 때, system response에서 ‘*I’m sorry. There are no
modern European restaurant*’ 으로 생성

## MultiWOZ Benchmarks Performance

- DST(Dialogue State Tracking), DCTG(Dialogue-Context-to-Text Generation)

### DST(Dialogue State Tracking)

![스크린샷 2023-03-20 오후 10.57.48.png](/assets/img/content/TOD/7.png)

- 평가 지표는 Joint Accuracy, Slot Accuracy
- 성능이 떨어지지만 최신 모델을 사용한 것에 의미가 크다.

### DCTG(Dialogue-Context-to-Text Generation)

![스크린샷 2023-03-20 오후 11.02.04.png](/assets/img/content/TOD/Untitle_6.png)

- Dialogue-Context-to-Text Generation : dialogue policy 와 system response generation module
- ground-truth DS와 ground- truth database query 결과가 주어질 때, system response의 품질을 측정하기 위한 것.
- BLEU 점수가 낮은 이유는 GPT-2는 데이터 셋에 없는 단어를 만들어내는 경우가 있기 때문.

## Conclusion

- 외부 시스템과 통합하기 쉽고, 시스템이 특정 응답을 생성하는 이유를 해석하기 쉽다는 것을 보여줬다.
- large-scale pre-trained LM을 end-to-end에서 채택하는 것을 보여줬다.

---

## 출처

- 논문
    
    TODS-MultiWOZ 논문 : [https://arxiv.org/pdf/1810.00278.pdf](https://arxiv.org/pdf/1810.00278.pdf) 
    End-to-End GPT-2 논문: [https://aclanthology.org/2020.acl-main.54.pdf](https://aclanthology.org/2020.acl-main.54.pdf)
    
- 참고한 블로그
    
    [https://hijigoo.github.io/nlp/2020/05/16/dialog-system-01/](https://hijigoo.github.io/nlp/2020/05/16/dialog-system-01/)
    
    [https://smilegate.ai/2022/07/21/%EC%9E%90%EB%84%A4-%EC%A7%80%EA%B8%88-%EC%9E%98%ED%[…]EC%9E%88%EB%8A%94%EA%B2%90%EA%B0%80-in-goal-oriented-dialogue/](https://smilegate.ai/2022/07/21/%EC%9E%90%EB%84%A4-%EC%A7%80%EA%B8%88-%EC%9E%98%ED%95%98%EA%B3%A0-%EC%9E%88%EB%8A%94%EA%B2%90%EA%B0%80-in-goal-oriented-dialogue/)
    
    [https://d2.naver.com/helloworld/2110494?fbclid=IwAR3bksWSGFAOYzVABeKmqT0nGJ77dtalbeLf118HVVzBacTQ-5_KKn8Mdp8](https://d2.naver.com/helloworld/2110494?fbclid=IwAR3bksWSGFAOYzVABeKmqT0nGJ77dtalbeLf118HVVzBacTQ-5_KKn8Mdp8)
    
    [https://wdprogrammer.tistory.com/83](https://wdprogrammer.tistory.com/83)
    

---