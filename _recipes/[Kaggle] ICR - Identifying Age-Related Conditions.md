---
title: "[Kaggle] ICR - Identifying Age-Related Conditions"
image: 
  path: /assets/img/content/pro4/1.png
  thumbnail: /assets/img/content/pro4/1.png
---

**ìš”ì•½**

- ìµëª…í™”ëœ ê°œì¸ ê±´ê°• ì •ë³´ë¥¼ í†µí•´ ì§ˆë³‘ ì§„ë‹¨ì„ ì˜ˆì¸¡í•˜ëŠ” ëŒ€íšŒ
- í”¼í—˜ìžê°€ ì´ëŸ¬í•œ ì§ˆí™˜ ì¤‘ í•˜ë‚˜ë¡œ ì§„ë‹¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” binary classification ë¬¸ì œ

**ì—­í• **

- PCAë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¨ì› ì¶•ì†Œí•˜ì—¬ í‰ê°€ ì§€í‘œ ê°’ í™•ì¸
- AutoMLìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì°¾ëŠ” ì—­í• 

ì„±ê³¼

- Leaderboard Score : 0.46
- Cross Validation Score : 0.338992

**ê¸°ê°„**

- 2023.06 ~ 2023.08

**GitHub ë§í¬**

[https://github.com/darkhairlove/Kaggle_ICR](https://github.com/darkhairlove/Kaggle_ICR)

- [ëŒ€íšŒ ë§í¬](https://www.kaggle.com/competitions/icr-identify-age-related-conditions)


# ëŒ€íšŒ ë°°ê²½

- í˜„ìž¬ ë…¸í™”ëŠ” ì „ ì„¸ê³„ ì¸êµ¬ì˜ ì£¼ìš” ì‚¬ë§ ì›ì¸ ì¤‘ í•˜ë‚˜ë¡œ ë‹¤ì–‘í•œ ì§ˆë³‘ê³¼ ê´€ë ¨ì´ ìžˆìŠµë‹ˆë‹¤.
- ë…¸í™”ì™€ ê´€ë ¨ëœ ì§ˆë³‘ì„ ì˜ˆë°©í•˜ê³  ì¹˜ë£Œí•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì°¾ê³  ìžˆìŠµë‹ˆë‹¤.
- ë¹…ë°ì´í„°ì™€ ì¸ê³µì§€ëŠ¥ì€ ë…¸í™”ì™€ ê´€ë ¨ëœ ì§ˆë³‘ì„ ì˜ˆë°©í•˜ê³  ì¹˜ë£Œí•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

# ì§„ë‹¨ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„œ

## ë°ì´í„°

- `train.csv`
    - `Id`Â ê° ê´€ì¸¡ê°’ì— ëŒ€í•œ ê³ ìœ  ì‹ë³„ìžìž…ë‹ˆë‹¤.
    - `AB-GL`Â ìµëª…í™”ëœ 56ê°œì˜ ê±´ê°• íŠ¹ì„±. categoricalì¸Â `EJ`ë¥¼ ì œì™¸í•˜ê³  ëª¨ë‘ ìˆ«ìžìž…ë‹ˆë‹¤.
    - `class`Â binary target :Â `1`ì€ í”¼í—˜ìžê°€ ì„¸ ê°€ì§€ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¡œ ì§„ë‹¨ë°›ì•˜ìŒì„ ë‚˜íƒ€ë‚´ê³ ,Â `0`ì€ ì§„ë‹¨ë°›ì§€ ì•Šì•˜ìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
- `test.csv`Â : í”¼í—˜ìžê°€ ë‘Â `class`Â ê°ê°ì— ì†í•  í™•ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒ
- `greeks.csv`Â - í›ˆë ¨ ì§‘í•©ì—ë§Œ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ë³´ì¡° metadata
    - `Alpha`Â : ì—°ë ¹ ê´€ë ¨ ì¡°ê±´ì´ ìžˆëŠ” ê²½ìš° í•´ë‹¹ ìœ í˜•ì„ ì‹ë³„í•©ë‹ˆë‹¤.
        - `A`Â : ì—°ë ¹ ê´€ë ¨ ì¡°ê±´ì´ ì—†ìŠµë‹ˆë‹¤. í´ëž˜ìŠ¤Â `0`ì— í•´ë‹¹í•©ë‹ˆë‹¤.
        - `B, D, G`Â : ì„¸ ê°€ì§€ ì—°ë ¹ ê´€ë ¨ ì¡°ê±´. í´ëž˜ìŠ¤Â `1`ì— í•´ë‹¹í•©ë‹ˆë‹¤.
    - `Beta`,Â `Gamma`,Â `Delta`Â : ì„¸ ê°€ì§€ ì‹¤í—˜ íŠ¹ì„±ìž…ë‹ˆë‹¤.
    - `Epsilon`Â : ì´ í”¼í—˜ìžì— ëŒ€í•œ ë°ì´í„°ê°€ ìˆ˜ì§‘ëœ ë‚ ì§œìž…ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ëª¨ë“  ë°ì´í„°ëŠ” í›ˆë ¨ ì„¸íŠ¸ê°€ ìˆ˜ì§‘ëœ í›„ì— ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.

## EDA

- ê²°ì¸¡ì¹˜ í™•ì¸ ê²°ê³¼
    
    ```python
    BQ       60
    CB        2
    CC        3
    DU        1
    EL       60
    FC        1
    FL        1
    FS        2
    GL        1
    ```
    
- Class ë³„ë¡œ `greeks.csv`ì— ìžˆëŠ” `Beta`, `Gamma`, `Delta` ì˜ ë¶„í¬ë¥¼ Bar Plotìœ¼ë¡œ í™•ì¸
    
    ![__results___25_0.png](/assets/img/content/pro4/2.png)
    
- ê° Cloumn ë³„ë¡œ regplotì„ í™•ì¸ â†’ ìƒê´€ê´€ê³„ê°€ ìžˆëŠ” Cloumnê³¼ ì—†ëŠ” Cloumnì„ í™•ì¸
    
    ![__results___26_0.png](/assets/img/content/pro4/3.png)
    
- ížˆíŠ¸ë§µì„ í™•ì¸í•˜ì—¬ Correlation í™•ì¸

![__results___28_0.png](/assets/img/content/pro4/4.png)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2023-08-04 á„‹á…©á„’á…® 4.29.59.png](/assets/img/content/pro4/5.png)

## Preprocessing & Feature Engineering

### Preprocessing features

- `KNNImputer`
    - ê²°ì¸¡ì¹˜ ë³´ê°„, â€˜EJâ€™ columnì€ ì œì™¸í•˜ê³  ì‚¬ìš©
        
        ```python
        imp = KNNImputer()
        X_train_1 = imp.fit_transform(X_train)
        X_test_1 = imp.transform(X_test)
        
        tmp1 = pd.DataFrame(columns=X_train.columns, data = X_train_1)
        X_train = pd.concat([tmp1], axis=1)
        
        tmp2 = pd.DataFrame(columns=X_test.columns, data = X_test_1)
        X_test = pd.concat([tmp2], axis=1)
        ```
        
    - `KNNImputer` ì‚¬ìš©í•œ ì´ìœ 
        
        ê° ì»¬ëŸ¼ì˜ ë°ì´í„°ëŠ” ìµëª…í™”ëœ ê±´ê°• íŠ¹ì„±ì„ ì˜ë¯¸í•˜ê³ , ì´ê²ƒì´ ìˆ«ìžë¡œ ë³€í™˜ëœ ìƒíƒœìž…ë‹ˆë‹¤.
        ë”°ë¼ì„œ ê°ê°ì˜ ìˆ«ìžê°€ ë‹¨ìˆœí•œ ìˆ«ìžê°€ ì•„ë‹Œ íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì˜ë¯¸ê°€ ìžˆê¸° ë•Œë¬¸ì—, ê²°ì¸¡ì¹˜ë¥¼ ë³´ê°„í•˜ëŠ” ë°©ë²•ì„ ìˆ«ìžì˜ íŠ¹ì„±ì´ ë°˜ì˜ë  ë°©ë²•ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        
        `KNNImputer` ëŠ” KNN(K-Nearest Neighbor)ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ë³´ê°„í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ê°€ê¹Œìš´ ì´ì›ƒì˜ ìˆ˜ë¥¼ ì •í•˜ê³  ê·¸ ì´ì›ƒë“¤ì„ ì´ìš©í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš°ëŠ” ë°©ì‹ìž…ë‹ˆë‹¤. ì¦‰, KNN ì•Œê³ ë¦¬ì¦˜ì€ ê±°ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.
        

### Feature Engineering

- `Label Encoding`
    - â€˜EJâ€™ columnì˜ unique ê°’ A, Bë¥¼ ê°ê° 0ê³¼ 1ë¡œ ë³€í™˜
        
        ```python
        train['EJ'] = train['EJ'].replace({'A': 0, 'B': 1})
        test['EJ' ]= test['EJ'].replace({'A': 0, 'B': 1})
        ```
        
    - greeksì˜ â€™Epsilonâ€™ ì œì™¸í•œ ë‚˜ë¨¸ì§€ cloumnì— LabelEncoder ì ìš©
        - `sklearn`ì˜ preprocessing í•¨ìˆ˜ ì¤‘ LabelEncoder
            
            ```python
            greeks['Epsilon']= 0
            
            cols = greeks.columns
            
            for colin cols:
                le = LabelEncoder()
                greeks[col] = le.fit_transform(greeks[col])
            ```
            
    - ë‚˜ë¨¸ì§€ â€˜Idâ€™ ë° â€˜Classâ€™ column ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ featureë“¤ì€ ëª¨ë‘ numericí•œ ê°’
- `StandardScaler`
    - `sklearn`ìœ¼ë¡œ Data Scaling
        
        ```python
        sc = StandardScaler() # MinMaxScaler or StandardScaler or RobustScaler
        X_train[numeric_columns] = sc.fit_transform(X_train[numeric_columns])
        X_test[numeric_columns] = sc.transform(X_test[numeric_columns])
        ```
        
    - `StandardScaler`ì„ ì‚¬ìš©í•œ ì´ìœ 
        
        ê±°ë¦¬ ê¸°ë°˜ì˜ ëª¨ë¸ë§ì„ í•  ë•Œ, ìƒëŒ€ì ìœ¼ë¡œ ë²”ìœ„ê°€ ë„“ì€ ë³€ìˆ˜ê°€ ìžˆë‹¤ë©´, ê±°ë¦¬ ê³„ì‚°í•˜ëŠ” ê³¼ì •ì—ì„œ ë” ë§Žì€ ê¸°ì—¬ë¥¼ í•˜ê²Œ ë˜ì–´ ì¤‘ìš”í•œ ë³€ìˆ˜ ë˜ëŠ” ì˜í–¥ë ¥ì´ ë†’ì€ ë³€ìˆ˜ë¡œ ì¸ì‹ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì§€ë¥¼ ë§‰ê¸° ìœ„í•´ ì ìš©í–ˆìŠµë‹ˆë‹¤. `StandardScaler`ëŠ” í‰ê· ì´ 0, ë¶„ì‚°ì´ 1ì¸ ì •ê·œë¶„í¬ë¥¼ ë„ë„ë¡ ë°ì´í„°ë¥¼ í‘œì¤€í™”í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.
        
- `Oversampling`
    - `greeks.Alpha`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ `SMOTE`
        
        ```python
        X_over, y_over = SMOTE(random_state=42).fit_resample(train, greeks.Alpha)
        ```
        
    - ì˜¤ë²„ìƒ˜í”Œë§ ì „ shape ì²´í¬:  `(617,)` â†’ ì˜¤ë²„ìƒ˜í”Œë§ í›„ shape ì²´í¬:  `(2036,)`
        
        ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2023-08-04 á„‹á…©á„’á…® 4.56.12.png](/assets/img/content/pro4/6.png)
        
    - `Oversampling` ìœ¼ë¡œ `SMOTE` ì‚¬ìš©í•œ ì´ìœ 
        
        ë‚®ì€ ë¹„ìœ¨ë¡œ ì¡´ìž¬í•˜ëŠ” í´ëž˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ K-NN ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ ìƒˆë¡­ê²Œ ìƒì„±í•˜ëŠ” ë°©ë²•ìž…ë‹ˆë‹¤. ì´ì— ë”°ë¼ ê³¼ì í•© ë°œìƒ ê°€ëŠ¥ì„±ì´ ë‹¨ìˆœ ë¬´ìž‘ìœ„ ë°©ë²•ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê³¼ì í•© ë°œìƒ ê°€ëŠ¥ì„±ì„ ê°€ìž¥ ë‚®ì¶”ê¸° ìœ„í•´ `SMOTE` ê¸°ë²•ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
        
- PCA, VIF
    - PCA : ì°¨ì› ì¶•ì†Œì™€ ë³€ìˆ˜ ì¶”ì¶œ ê¸°ë²•ìœ¼ë¡œ ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ ë§Žì•„ ìƒˆë¡œìš´ ë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ëª¨ë¸ë§í•˜ëŠ” ë°©ë²•
        
        ```python
        from sklearn.decomposition import PCA
        pca = PCA(n_components=35)
        pca.fit(X_train)
        X_train = pca.transform(X_train)
        X_test  = pca.transform(X_test)
        # 29ë²ˆì§¸ê¹Œì§€ Explained Varianceì˜ ëˆ„ì í•©ì´ 0.861220 
        ```
        
        `X_train.shape (2036, 29)`
        
        ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2023-08-01 á„‹á…©á„’á…® 11.32.26.png](/assets/img/content/pro4/7.png)
        
    - VIF : ë‹¤ì¤‘íšŒê·€ëª¨ë¸ì—ì„œ ë…ë¦½ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ê°€ ìžˆëŠ”ì§€ ë³´ëŠ” ì²™ë„ìž…ë‹ˆë‹¤. VIFê°€ 10ì´ ë„˜ìœ¼ë©´ ë‹¤ì¤‘ê³µì„ ì„±ì´ ìžˆë‹¤ê³  íŒë‹¨ì´ ë˜ê³  5ë¥¼ ë„˜ìœ¼ë©´ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ì¤‘ê³µì‚°ì„±(Multicollinearity)ëŠ” ë…ë¦½ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ê°€ ìžˆë‹¤ëŠ” ê²ƒìž…ë‹ˆë‹¤.
        
        ```python
        def check_vif(df):
            vifs = [variance_inflation_factor(df, i) for i in range(df.shape[1])]
            vif_df = pd.DataFrame({"features":df.columns, "VIF" : vifs})
            vif_df = vif_df.sort_values(by="VIF", ascending=False)
            remove_col = vif_df.iloc[0, 0]
            top_vif = vif_df.iloc[0, 1]
            return vif_df, remove_col, top_vif
        
        top_vif = 100
        
        while(top_vif > 5):
             vif_df, remove_col, top_vif = check_vif(X_train)
             print(vif_df)
             print(remove_col, top_vif)
             if top_vif < 5:
                 break
        		 X_train = X_train.drop(columns=remove_col)
        X_test = pd.DataFrame(data=X_test, columns=X_train.columns)
        ```
        
        `X_train.shape (2036, 51)`
        
    - ìµœì¢… ëª¨ë¸ì— PCA, VIFë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì€ ì´ìœ 
        
        Columnì„ ì¤„ì´ê¸° ìœ„í•´ ì‚¬ìš©í–ˆì§€ë§Œ, balancedloglossê°€ ì¢‹ì•„ì§€ì§€ ì•Šì•„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        ê¸°ë³¸ ëª¨ë“  ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œì™€ PCAì™€ VIFë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ë¹„êµí•œ ê²°ê³¼ìž…ë‹ˆë‹¤.
        
        |              | XGB      | LGBM     | CatBoost | RandomForest |
        | ------------ | -------- | -------- | -------- | ------------ |
        | ì¼ë°˜(Defult) | 1.000901 | 0.670095 | 0.890632 | 0.636166     |
        | VIF          | 0.924561 | 0.678577 | 0.966972 | 0.814292     |
        | PCA          | 1.246885 | 0.992418 | 1.348672 | 1.272332     |

## Modeling

### Cross Validation : StratifiedKFold ì‚¬ìš©

- KFold : êµì°¨ê²€ì¦ì„ ìœ„í•´ì„œ ê°€ìž¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë°©ì‹
    
    ```python
    kf = KFold(n_splits = 5, shuffle = True, random_state = 721)
    ```
    
- StratifiedKFold : ë°ì´í„°ì…‹ì„ í•™ìŠµ/ê²€ì¦ ì…‹ìœ¼ë¡œ ë‚˜ëˆŒ ë•Œ ë°ì´í„°ì…‹ì˜ classë³„ ë¹„ìœ¨ì„ ë™ì¼í•˜ê²Œ ê°€ì ¸ê°€ë„ë¡ í•˜ëŠ” ê²ƒ
    
    ```python
    kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 721)
    
    for train_index, valid_index in kf.split(X_train, y_train):
    ```
    
- MultilabelstratifiedKFold: multi-labelì„ ê°–ëŠ” ë°ì´í„°ë“¤ì˜ ë¹„ìœ¨ì„ ì¼ì •í•˜ê²Œ ë‚˜ëˆŒ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
`greeks`ì—ì„œ â€˜Alphaâ€™, â€˜Betaâ€™, â€˜Gammaâ€™, â€˜Deltaâ€™ columns  ê¸°ì¤€.
    
    ```python
    kf = MultilabelStratifiedKFold(n_splits = 5, shuffle = True, random_state = 721)
    
    for train_index, valid_index in kf.split(train, greeks.iloc[:,1:-1]):
    ```
    
- StratifiedKFoldì„ ì‚¬ìš©í•œ ì´ìœ 
    
    ê° ëª¨ë¸ì„ ë¹„êµí•œ ê²°ê³¼ balancedloglossê°€ StratifiedKFold ì¢‹ì•„ì„œ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤.
    
    |                           | XGB      | LGBM     | CatBoost | RandomForest |
    | ------------------------- | -------- | -------- | -------- | ------------ |
    | KFold                     | 0.746435 | 0.661613 | 0.916079 | 1.195992     |
    | StratifiedKFold           | 0.559826 | 0.585273 | 1.000901 | 1.128134     |
    | MultilabelstratifiedKFold | 0.661613 | 0.712506 | 1.119652 | 1.162062     |

### Ensemble : CV Stacking

- ê°œë³„ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë°ì´í„°ë¥¼ ë‹¤ì‹œ training setìœ¼ë¡œ ì‚¬ìš©í•´ì„œ í•™ìŠµ
- ëª¨ë¸ ê°œì„  í›„ ìµœì¢… ê°œë³„ ëª¨ë¸ ë° ë©”íƒ€ ëª¨ë¸
    - ê°œë³„ ëª¨ë¸
        - LGBMClassifier
        - CatBoostClassifier
        - HistGradientBoostingClassifier
        - RandomForestClassifier
    - ë©”íƒ€ ëª¨ë¸
        - LGBMClassifier
- ì›ë³¸ í•™ìŠµ ë°ì´í„° Shape: `(2036, 56)` ì›ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° Shape: `(5, 56)` 
â†’ Stacking í•™ìŠµ ë°ì´í„° Shape: `(2036, 4)` Stacking í…ŒìŠ¤íŠ¸ ë°ì´í„° Shape: `(5, 4)`

### Hyperparameter

- [Optuna](https://github.com/darkhairlove/Kaggle_ICR/blob/main/Hyperparameter/Optuna_Automl.ipynb)Â ðŸ”—
- [Flaml](https://github.com/darkhairlove/Kaggle_ICR/blob/main/Hyperparameter/Flaml_Automl.ipynb)Â ðŸ”—

# ê²°ê³¼

- Leaderboard Score : 0.46
- Cross Validation Score : 0.338992

# í•œê³„ì 

- Ensemble ê¸°ë²•ì„ ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©í•˜ì§€ ëª»í•œ ê²ƒì´ í•œê³„ì ì´ê³ , ì´ ëŒ€íšŒì—ì„œ Automl ì¤‘ í•˜ë‚˜ì¸ autogluonì„ ì‚¬ìš©í•˜ì§€ ëª»í•˜ê²Œ ë˜ì–´ì„œ ì•„ì‰¬ì› ìŠµë‹ˆë‹¤.
- `greeks` ë°ì´í„°ë¥¼ ë‹¤ì–‘í•˜ê²Œ í™œìš©í•˜ì§€ ëª»í•œ ê²ƒì´ í•œê³„ì ì´ê³  ë‹¤ë¥¸ ì°¸ê°€ìžì˜ ì½”ë“œë¥¼ ì°¸ê³ í–ˆì„ ë•Œ, featureë¥¼ ì„ ë³„í•˜ëŠ” ì´ìœ ì— ëŒ€í•œ ê·¼ê±°ë¥¼ ì°¾ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤.

# ëŠë‚€ì 

- Kaggleë¡œ ëŒ€íšŒë¥¼ ì²˜ìŒì´ì—ˆì§€ë§Œ, í•¨ê»˜ Jupyter notebookì„ ê³µìœ í•´ì„œ ê³µë™ ìž‘ì—…í•˜ê¸° ìˆ˜ì›”í–ˆìŠµë‹ˆë‹¤.
- ì œí•œì´ ë§Žì´ ë˜ëŠ” ëŒ€íšŒì¸ ë§Œí¼ ì£¼ì–´ì§„ ë°ì´í„°ì™€ ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ì–´ë ¤ì› ìŠµë‹ˆë‹¤.
- í‰ê°€ ì§€í‘œì¸ balanced logarithmic lossê°€ ì–´ë–¤ ê²ƒì¸ì§€ ì•Œì•„ ê°ˆ ìˆ˜ ìžˆë˜ ê³„ê¸°ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.